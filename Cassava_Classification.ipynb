{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Imports\nimport os\nimport sys\nimport glob\nimport torch\nimport torchvision\n\nimport numpy    as np\nimport datetime as dt\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport matplotlib.pyplot   as plt\n\nfrom PIL               import Image\nfrom torch.utils.data  import Dataset\nfrom torch.autograd    import Variable\nfrom torch.optim       import lr_scheduler\n\nfrom torch.utils.data  import Dataset, DataLoader\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torchvision       import transforms, datasets, models\nfrom os                import listdir, makedirs, getcwd, remove\nfrom os.path           import isfile, join, abspath, exists, isdir, expanduser\n\n\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-23T14:59:25.400289Z","iopub.execute_input":"2021-05-23T14:59:25.400602Z","iopub.status.idle":"2021-05-23T14:59:26.856635Z","shell.execute_reply.started":"2021-05-23T14:59:25.400575Z","shell.execute_reply":"2021-05-23T14:59:26.855878Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"****Reading the Dataset****","metadata":{}},{"cell_type":"code","source":"data_path = \"../input/ammi-2021-convnets/\"\ntrain_path = join(data_path, \"train/train\")\ntest_path = join(data_path,\"test/test\")\nextraimage_path = join(data_path, \"extraimages/extraimages\")","metadata":{"execution":{"iopub.status.busy":"2021-05-23T14:59:26.857724Z","iopub.execute_input":"2021-05-23T14:59:26.858081Z","iopub.status.idle":"2021-05-23T14:59:26.865242Z","shell.execute_reply.started":"2021-05-23T14:59:26.858047Z","shell.execute_reply":"2021-05-23T14:59:26.862613Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"****Preprocessing****","metadata":{}},{"cell_type":"code","source":"# Transformations for both the training and testing data\nmean=[0.485, 0.456, 0.406]\nstd=[0.229, 0.224, 0.225]\nnormalize = transforms.Normalize(mean=mean, std=std)\n\n\n\ntrain_transforms = transforms.Compose([\n                                       transforms.RandomResizedCrop(500),\n                                       transforms.RandomHorizontalFlip(),\n                                       transforms.RandomVerticalFlip(),\n                                       transforms.ToTensor(),\n                                      normalize])\n\ntest_transforms = transforms.Compose([ \n                                      transforms.Resize((500, 500)),\n                                       transforms.ToTensor(),\n                                       normalize])\n\n","metadata":{"execution":{"iopub.status.busy":"2021-05-23T16:07:51.043416Z","iopub.execute_input":"2021-05-23T16:07:51.043738Z","iopub.status.idle":"2021-05-23T16:07:51.050538Z","shell.execute_reply.started":"2021-05-23T16:07:51.043706Z","shell.execute_reply":"2021-05-23T16:07:51.049637Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"class CassavaDataset(Dataset):\n    def __init__(self, path, transform=None):\n        self.classes = os.listdir(path)\n        self.path = [f\"{path}/{className}\" for className in self.classes]\n        self.file_list = [glob.glob(f\"{x}/*\") for x in self.path]\n        self.transform = transform\n\n        files = []\n        for i, className in enumerate(self.classes):\n            for fileName in self.file_list[i]:\n                files.append([i, className, fileName])\n        self.file_list = files\n        files = None\n\n    def __len__(self):\n        return len(self.file_list)\n\n    def __getitem__(self, idx):\n        fileName = self.file_list[idx][2]\n        classCategory = self.file_list[idx][0]\n        im = Image.open(fileName)\n        if self.transform:\n            im = self.transform(im)\n            \n        return im.view(3, 500, 500), classCategory, fileName","metadata":{"execution":{"iopub.status.busy":"2021-05-23T16:07:55.912364Z","iopub.execute_input":"2021-05-23T16:07:55.912666Z","iopub.status.idle":"2021-05-23T16:07:55.920484Z","shell.execute_reply.started":"2021-05-23T16:07:55.912638Z","shell.execute_reply":"2021-05-23T16:07:55.919629Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"train_data = CassavaDataset(train_path, transform=train_transforms)\ntest_data = CassavaDataset(test_path, transform=test_transforms)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T16:07:56.512383Z","iopub.execute_input":"2021-05-23T16:07:56.512700Z","iopub.status.idle":"2021-05-23T16:07:56.557451Z","shell.execute_reply.started":"2021-05-23T16:07:56.512673Z","shell.execute_reply":"2021-05-23T16:07:56.556738Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"****Split train data to train and valid****","metadata":{}},{"cell_type":"code","source":"validation_split = .2\nshuffle_dataset = True\nrandom_seed= 42\n\n# Creating data indices for training and validation splits:\ndataset_size = len(train_data)\nindices = list(range(dataset_size))\nsplit = int(np.floor(validation_split * dataset_size))\n\nif shuffle_dataset :\n    np.random.seed(random_seed)\n    np.random.shuffle(indices)\n\ntrain_indices, val_indices = indices[split:], indices[:split]","metadata":{"execution":{"iopub.status.busy":"2021-05-23T16:07:58.432452Z","iopub.execute_input":"2021-05-23T16:07:58.432757Z","iopub.status.idle":"2021-05-23T16:07:58.439381Z","shell.execute_reply.started":"2021-05-23T16:07:58.432729Z","shell.execute_reply":"2021-05-23T16:07:58.438422Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"****Data loader****","metadata":{}},{"cell_type":"code","source":"# Creating PT data samplers and loaders:\ntrain_sampler = SubsetRandomSampler(train_indices)\nvalid_sampler = SubsetRandomSampler(val_indices)\n\n\ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size=16,\n                                             sampler=train_sampler)\nvalid_loader = torch.utils.data.DataLoader(train_data, batch_size=16,\n                                             sampler=valid_sampler)\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=16)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T16:08:02.812627Z","iopub.execute_input":"2021-05-23T16:08:02.812942Z","iopub.status.idle":"2021-05-23T16:08:02.819203Z","shell.execute_reply.started":"2021-05-23T16:08:02.812912Z","shell.execute_reply":"2021-05-23T16:08:02.818328Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"****Device configuration****","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2021-05-23T14:59:30.469372Z","iopub.execute_input":"2021-05-23T14:59:30.471905Z","iopub.status.idle":"2021-05-23T14:59:30.562250Z","shell.execute_reply.started":"2021-05-23T14:59:30.471860Z","shell.execute_reply":"2021-05-23T14:59:30.561293Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"****Model****","metadata":{}},{"cell_type":"code","source":"# model = torchvision.models.resnet18(pretrained=True)\n# model = torchvision.models.resnet50(pretrained=True)\n# model = torchvision.models.resnet101(pretrained=True)\n\nmodel = torchvision.models.resnext50_32x4d(pretrained=True)\n#model = torchvision.models.resnext101_32x8d(pretrained=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T14:59:35.789088Z","iopub.execute_input":"2021-05-23T14:59:35.789404Z","iopub.status.idle":"2021-05-23T14:59:40.191783Z","shell.execute_reply.started":"2021-05-23T14:59:35.789374Z","shell.execute_reply":"2021-05-23T14:59:40.190853Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth\" to /root/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/95.8M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68932248df4941b8b7611945b747c59e"}},"metadata":{}}]},{"cell_type":"code","source":"# for param in model.parameters():\n            \n#     param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2021-05-23T14:59:41.859254Z","iopub.execute_input":"2021-05-23T14:59:41.859565Z","iopub.status.idle":"2021-05-23T14:59:41.865327Z","shell.execute_reply.started":"2021-05-23T14:59:41.859537Z","shell.execute_reply":"2021-05-23T14:59:41.864613Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# change the Dimensions of the last layer \nnum_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(num_ftrs, 5)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T14:59:42.438781Z","iopub.execute_input":"2021-05-23T14:59:42.439107Z","iopub.status.idle":"2021-05-23T14:59:42.446130Z","shell.execute_reply.started":"2021-05-23T14:59:42.439078Z","shell.execute_reply":"2021-05-23T14:59:42.445316Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"****Train_Test Function****","metadata":{}},{"cell_type":"code","source":"def train_test(model, criterion, train_loader,val_loader, optimizer, num_epochs, best_acc= 0):\n    \"\"\"Simple training loop for a PyTorch model.\"\"\" \n    \n    \n    # Move model to the device (CPU or GPU).\n    model.to(device)\n    \n    best_accur = best_acc\n    best_acc_epoch = 0\n    # Exponential moving average of the loss.\n    ema_loss = None\n\n    print('----- Training Loop -----')\n    # Loop over epochs.\n    for epoch in range(num_epochs):\n        \n        # Make sure model is in training mode.\n        model.train()\n        \n        correct_train = 0\n        # Loop over data.\n        for batch_idx, (features, target,_) in enumerate(train_loader):\n            \n            # Forward pass.\n            output = model(features.to(device))\n            loss = criterion(output.to(device), target.to(device))\n\n              # Backward pass.\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            \n          # NOTE: It is important to call .item() on the loss before summing.\n            if ema_loss is None:\n                ema_loss = loss.item()\n            else:\n                ema_loss += (loss.item() - ema_loss) * 0.01 \n\n            # Get the label corresponding to the highest predicted probability.\n            pred = output.argmax(dim=1, keepdim=True)\n\n            # Count number of correct predictions.\n            correct_train += pred.cpu().eq(target.view_as(pred)).sum().item()\n\n        # Print out progress the end of epoch.\n        \n        print('Epoch: {} \\tLoss: {:.6f}'.format(epoch, ema_loss),)\n        \n\n        \"\"\"Measures the accuracy of a model on a validation.\"\"\"\n    \n        # Make sure the model is in evaluation mode.\n        model.eval()\n    \n        correct_test = 0\n        \n        #print('----- Model Evaluation -----')\n    \n        # We do not need to maintain intermediate activations while testing.\n        \n        with torch.no_grad():\n\n          # Loop over test data.\n          for features, target,_ in val_loader:\n\n                # Forward pass.\n                output = model(features.to(device))\n\n                # Get the label corresponding to the highest predicted probability.\n                pred = output.argmax(dim=1, keepdim=True)\n\n                # Count number of correct predictions.\n                correct_test += pred.cpu().eq(target.view_as(pred)).sum().item()\n      \n        # Print test accuracy.\n        percent_train = 100. * correct_train / (len(train_loader.sampler) )\n        print(f'Train accuracy: {correct_train} / {len(train_loader.sampler) } ({percent_train:.0f}%)')\n        \n        percent_test = 100. * correct_test / (len(val_loader.sampler) )\n        print(f'Test accuracy: {correct_test} / {len(val_loader.sampler) } ({percent_test:.0f}%)')\n        \n        print(\"\")\n        if(percent_test > best_accur):\n            \n            torch.save(model, 'model.ckpt')\n            \n            best_accur = percent_test\n            best_acc_epoch = epoch\n        scheduler.step()\n            \n    return best_accur, best_acc_epoch\n","metadata":{"execution":{"iopub.status.busy":"2021-05-23T14:59:47.079665Z","iopub.execute_input":"2021-05-23T14:59:47.080024Z","iopub.status.idle":"2021-05-23T14:59:47.094139Z","shell.execute_reply.started":"2021-05-23T14:59:47.079974Z","shell.execute_reply":"2021-05-23T14:59:47.093233Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# def train(model, criterion, data_loader, optimizer, num_epochs):\n#     \"\"\"Simple training loop for a PyTorch model.\"\"\" \n    \n#     # Make sure model is in training mode.\n#     model.train()\n    \n#     # Move model to the device (CPU or GPU).\n#     model.to(device)\n    \n#     # Exponential moving average of the loss.\n#     ema_loss = None\n\n#     print('----- Training Loop -----')\n#     # Loop over epochs.\n#     for epoch in range(num_epochs):\n        \n#       # Loop over data.\n#       for batch_idx, (features, target,_) in enumerate(data_loader):\n            \n#           # Forward pass.\n#         output = model(features.to(device))\n#         loss = criterion(output.to(device), target.to(device))\n\n#           # Backward pass.\n#         optimizer.zero_grad()\n#         loss.backward()\n#         optimizer.step()\n\n#       # NOTE: It is important to call .item() on the loss before summing.\n#         if ema_loss is None:\n#             ema_loss = loss.item()\n#         else:\n#             ema_loss += (loss.item() - ema_loss) * 0.01 \n\n#       # Print out progress the end of epoch.\n#       print('Epoch: {} \\tLoss: {:.6f}'.format(epoch, ema_loss),)\n  ","metadata":{"execution":{"iopub.status.busy":"2021-05-23T13:27:09.641878Z","iopub.execute_input":"2021-05-23T13:27:09.642218Z","iopub.status.idle":"2021-05-23T13:27:09.646202Z","shell.execute_reply.started":"2021-05-23T13:27:09.642188Z","shell.execute_reply":"2021-05-23T13:27:09.645357Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# def test(model, data_loader):\n#     \"\"\"Measures the accuracy of a model on a data set.\"\"\" \n#     # Make sure the model is in evaluation mode.\n#     model.eval()\n#     correct = 0\n#     print('----- Model Evaluation -----')\n#     # We do not need to maintain intermediate activations while testing.\n#     with torch.no_grad():\n        \n#         # Loop over test data.\n#         for features, target,_ in data_loader:\n          \n#             # Forward pass.\n#             output = model(features.to(device))\n            \n#             # Get the label corresponding to the highest predicted probability.\n#             pred = output.argmax(dim=1, keepdim=True)\n            \n#             # Count number of correct predictions.\n#             correct += pred.cpu().eq(target.view_as(pred)).sum().item()\n\n#     # Print test accuracy.\n#     percent = 100. * correct / (len(data_loader.sampler))\n#     print(f'Test accuracy: {correct} / {len(data_loader.sampler)} ({percent:.0f}%)')\n#     torch.save(model.state_dict(), 'model.ckpt')\n#     return percent","metadata":{"execution":{"iopub.status.busy":"2021-05-23T14:59:58.469060Z","iopub.execute_input":"2021-05-23T14:59:58.469382Z","iopub.status.idle":"2021-05-23T14:59:58.475633Z","shell.execute_reply.started":"2021-05-23T14:59:58.469354Z","shell.execute_reply":"2021-05-23T14:59:58.474816Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"****Loss function and Optimizer****","metadata":{}},{"cell_type":"code","source":"criterion = torch.nn.CrossEntropyLoss()\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = 7)\n","metadata":{"execution":{"iopub.status.busy":"2021-05-23T15:00:12.130440Z","iopub.execute_input":"2021-05-23T15:00:12.130781Z","iopub.status.idle":"2021-05-23T15:00:12.138471Z","shell.execute_reply.started":"2021-05-23T15:00:12.130751Z","shell.execute_reply":"2021-05-23T15:00:12.137464Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"****Training****","metadata":{}},{"cell_type":"code","source":"epochs = 10\ntrain_test(model, criterion, train_loader,valid_loader, optimizer, num_epochs = epochs, best_acc= 0)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T15:00:16.550289Z","iopub.execute_input":"2021-05-23T15:00:16.550720Z","iopub.status.idle":"2021-05-23T16:03:24.853561Z","shell.execute_reply.started":"2021-05-23T15:00:16.550682Z","shell.execute_reply":"2021-05-23T16:03:24.852878Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"----- Training Loop -----\nEpoch: 0 \tLoss: 0.627644\nTrain accuracy: 3539 / 4525 (78%)\nTest accuracy: 949 / 1131 (84%)\n\nEpoch: 1 \tLoss: 0.485048\nTrain accuracy: 3780 / 4525 (84%)\nTest accuracy: 1008 / 1131 (89%)\n\nEpoch: 2 \tLoss: 0.398012\nTrain accuracy: 3964 / 4525 (88%)\nTest accuracy: 1001 / 1131 (89%)\n\nEpoch: 3 \tLoss: 0.362393\nTrain accuracy: 3996 / 4525 (88%)\nTest accuracy: 995 / 1131 (88%)\n\nEpoch: 4 \tLoss: 0.313265\nTrain accuracy: 4067 / 4525 (90%)\nTest accuracy: 1017 / 1131 (90%)\n\nEpoch: 5 \tLoss: 0.253910\nTrain accuracy: 4138 / 4525 (91%)\nTest accuracy: 1017 / 1131 (90%)\n\nEpoch: 6 \tLoss: 0.228346\nTrain accuracy: 4188 / 4525 (93%)\nTest accuracy: 1026 / 1131 (91%)\n\nEpoch: 7 \tLoss: 0.208281\nTrain accuracy: 4199 / 4525 (93%)\nTest accuracy: 1023 / 1131 (90%)\n\nEpoch: 8 \tLoss: 0.215263\nTrain accuracy: 4205 / 4525 (93%)\nTest accuracy: 1027 / 1131 (91%)\n\nEpoch: 9 \tLoss: 0.234493\nTrain accuracy: 4188 / 4525 (93%)\nTest accuracy: 1022 / 1131 (90%)\n\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"(90.80459770114942, 8)"},"metadata":{}}]},{"cell_type":"markdown","source":"****Submission****","metadata":{}},{"cell_type":"code","source":"model = torch.load(\"./model.ckpt\")","metadata":{"execution":{"iopub.status.busy":"2021-05-23T16:09:31.443252Z","iopub.execute_input":"2021-05-23T16:09:31.443567Z","iopub.status.idle":"2021-05-23T16:09:31.533172Z","shell.execute_reply.started":"2021-05-23T16:09:31.443539Z","shell.execute_reply":"2021-05-23T16:09:31.532392Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# Make submission here\nmodel.eval()\nmodel.to(device)\nresult = []\nfile_names = []\nwith torch.no_grad():\n    for batch,_ ,names in test_loader:\n        output = model(batch.cuda()) \n        result.append(output.argmax(dim=1, keepdim=True))\n        file_names.append(names)\n\n\nimport pandas as pd\nsub = pd.read_csv(\"../input/ammi-2021-convnets/sample_submission_file.csv\")\nprint(sub.head())\nr = []\nf = []\nfor i, res in enumerate(result):\n    for j, res_1 in enumerate(res):\n        r.append(train_data.classes[res_1])\n        f.append(file_names[i][j].split('/')[-1])\n\nsub['Category'] = r\nsub['Id'] = f\n","metadata":{"execution":{"iopub.status.busy":"2021-05-23T16:09:32.602810Z","iopub.execute_input":"2021-05-23T16:09:32.603148Z","iopub.status.idle":"2021-05-23T16:10:24.149573Z","shell.execute_reply.started":"2021-05-23T16:09:32.603118Z","shell.execute_reply":"2021-05-23T16:10:24.148862Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"  Category              Id\n0     cbsd  test-img-0.jpg\n1      cmd  test-img-1.jpg\n2      cbb  test-img-2.jpg\n3      cmd  test-img-3.jpg\n4     cbsd  test-img-4.jpg\n","output_type":"stream"}]},{"cell_type":"markdown","source":"****Save the submission file****","metadata":{}},{"cell_type":"code","source":"sub.to_csv(\"sub.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T16:10:55.118439Z","iopub.execute_input":"2021-05-23T16:10:55.118755Z","iopub.status.idle":"2021-05-23T16:10:55.132501Z","shell.execute_reply.started":"2021-05-23T16:10:55.118718Z","shell.execute_reply":"2021-05-23T16:10:55.131814Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}